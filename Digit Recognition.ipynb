{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset in Keras\n",
    "\n",
    "The Keras deep learning library provides a convenience method for loading the MNIST dataset. \n",
    "\n",
    "The dataset is downloaded automatically the first time this function is called.\n",
    "\n",
    "This is very handy for developing and testing deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20edae27048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model with Multi-Layer Perceptrons\n",
    "\n",
    "We can get very good results using a very simple neural network model with a single hidden layer. We will create a simple multi-layer perceptron model that achieves an error rate of 1.74%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility to ensure results are reproducible\n",
    "seed = 26\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is structured as a 3-dimensional array of instance, image width and image height. For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\n",
    "\n",
    "We can do this transform easily using the reshape() function on the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are gray scale between 0 and 255. So we normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. So we use one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "We can easily do this using the built-in np_utils.to_categorical() helper function in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot 10th label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x12b80efa2e8>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f05f98>,\n",
       "  <matplotlib.axis.XTick at 0x12b80efe080>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f21e48>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f254e0>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f25b38>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f2b1d0>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f2b828>,\n",
       "  <matplotlib.axis.XTick at 0x12b80f2beb8>,\n",
       "  <matplotlib.axis.XTick at 0x12b80b02588>],\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlLP1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b80630be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create our simple neural network model. We will define our model in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "     #Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile network\n",
    "Before making network ready for training we added below things:\n",
    "\n",
    "1. A loss function: to measure how good the network is\n",
    "\n",
    "2. An optimizer: to update network as it sees more data and reduce loss value\n",
    "\n",
    "3. Metrics: to monitor performance of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit and evaluate the model. The model is fit over 10 epochs with updates every 100 images. The test data is used allowing us to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
    "\n",
    "Finally, the test dataset is used to evaluate the model and a classification error rate is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "17s - loss: 0.2320 - acc: 0.9336 - val_loss: 0.1114 - val_acc: 0.9656\n",
      "Epoch 2/10\n",
      "17s - loss: 0.0891 - acc: 0.9736 - val_loss: 0.0758 - val_acc: 0.9761\n",
      "Epoch 3/10\n",
      "17s - loss: 0.0567 - acc: 0.9833 - val_loss: 0.0684 - val_acc: 0.9772\n",
      "Epoch 4/10\n",
      "17s - loss: 0.0385 - acc: 0.9887 - val_loss: 0.0740 - val_acc: 0.9756\n",
      "Epoch 5/10\n",
      "17s - loss: 0.0270 - acc: 0.9921 - val_loss: 0.0670 - val_acc: 0.9795\n",
      "Epoch 6/10\n",
      "17s - loss: 0.0193 - acc: 0.9945 - val_loss: 0.0594 - val_acc: 0.9836\n",
      "Epoch 7/10\n",
      "17s - loss: 0.0135 - acc: 0.9965 - val_loss: 0.0589 - val_acc: 0.9818\n",
      "Epoch 8/10\n",
      "17s - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0614 - val_acc: 0.9827\n",
      "Epoch 9/10\n",
      "17s - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0627 - val_acc: 0.9823\n",
      "Epoch 10/10\n",
      "16s - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0640 - val_acc: 0.9821\n",
      "Baseline Error: 1.79%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=100, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Model\n",
    "\n",
    "The model is a simple neural network with one hidden layer with the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer.\n",
    "\n",
    "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model’s output prediction. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n",
    "\n",
    "This very simple network defined in very few lines of code achieves a respectable error rate of 1.91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we develop a CNN model.\n",
    "\n",
    "Keras does provide a lot of capability for creating convolutional neural networks.\n",
    "\n",
    "We will create a CNN for MNIST that use all of the aspects of a modern CNN implementation, including Convolutional layers, Pooling layers and Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Fix random seed for reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 58\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to load the MNIST dataset and reshape it so that it is suitable for training a CNN. \n",
    "\n",
    "In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In the case of MNIST where the pixel values are gray scale, the pixel dimension is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of model\n",
    "\n",
    "The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, with the size of 5×5 and a rectifier activation function.\n",
    "\n",
    "Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "\n",
    "The next layer is a regularization layer called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "\n",
    "Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    "\n",
    "Next a fully connected layer with 128 neurons and rectifier activation function.\n",
    "\n",
    "Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
    " \n",
    "The model is trained using logarithmic loss and the ADAM gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model the same way as before with the multi-layer perceptron. The CNN is fit over 5 epochs with a batch size of 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "230s - loss: 0.1906 - acc: 0.9450 - val_loss: 0.0652 - val_acc: 0.9777\n",
      "Epoch 2/5\n",
      "229s - loss: 0.0632 - acc: 0.9809 - val_loss: 0.0459 - val_acc: 0.9854\n",
      "Epoch 3/5\n",
      "229s - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0335 - val_acc: 0.9886\n",
      "Epoch 4/5\n",
      "230s - loss: 0.0332 - acc: 0.9896 - val_loss: 0.0336 - val_acc: 0.9888\n",
      "Epoch 5/5\n",
      "227s - loss: 0.0258 - acc: 0.9919 - val_loss: 0.0450 - val_acc: 0.9852\n",
      "CNN Error: 1.48%\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=100, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Convolutional Neural Network for MNIST\n",
    "\n",
    "We import classes and function then load and prepare the data the same as in the previous CNN example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Model\n",
    "\n",
    "This time we define a large CNN architecture with additional convolutional, max pooling layers and fully connected layers.\n",
    "\n",
    "Convolutional layer with 30 feature maps of size 5×5.\n",
    "\n",
    "Pooling layer taking the max over 2*2 patches.\n",
    "\n",
    "Convolutional layer with 15 feature maps of size 3×3.\n",
    "\n",
    "Pooling layer taking the max over 2*2 patches.\n",
    "\n",
    "Dropout layer with a probability of 20%.\n",
    "\n",
    "Flatten layer.\n",
    "\n",
    "Fully connected layer with 128 neurons and rectifier activation.\n",
    "\n",
    "Fully connected layer with 50 neurons and rectifier activation.\n",
    "\n",
    "Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "   # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 272s - loss: 0.3922 - acc: 0.8796 - val_loss: 0.1009 - val_acc: 0.9665\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1070s - loss: 0.0953 - acc: 0.9709 - val_loss: 0.0564 - val_acc: 0.9815\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 234s - loss: 0.0694 - acc: 0.9790 - val_loss: 0.0385 - val_acc: 0.9879\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0565 - acc: 0.9825 - val_loss: 0.0317 - val_acc: 0.9887\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0478 - acc: 0.9850 - val_loss: 0.0303 - val_acc: 0.9901\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 223s - loss: 0.0430 - acc: 0.9864 - val_loss: 0.0278 - val_acc: 0.9904\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 222s - loss: 0.0383 - acc: 0.9878 - val_loss: 0.0271 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 224s - loss: 0.0348 - acc: 0.9888 - val_loss: 0.0235 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 223s - loss: 0.0323 - acc: 0.9898 - val_loss: 0.0206 - val_acc: 0.9937\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 222s - loss: 0.0278 - acc: 0.9911 - val_loss: 0.0214 - val_acc: 0.9928\n",
      "Large CNN Error: 0.72%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate\n",
    "(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints accuracy on the training and validation datasets each epoch and a final classification error rate.\n",
    "\n",
    "This slightly larger model achieves the respectable classification error rate of 0.72%."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
